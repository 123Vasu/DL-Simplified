{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training and testing data\n",
    "train = pd.read_csv('F:\\Yash\\Dataset_SSOC\\written_name_train_v2.csv')\n",
    "valid = pd.read_csv('F:\\Yash\\Dataset_SSOC\\written_name_validation_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# To view first 6 images\n",
    "for i in range(6):\n",
    "    # plt.subplot(nrows, ncols, index)\n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    img_dir = 'F:\\Yash\\Dataset_SSOC\\train_v2\\train'+train.loc[i, 'FILENAME']\n",
    "    # cv2.imread(path=img_dir, flag=specifies the way in which image should be read)\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    # cv2.imread(X=data of the image, colormap instance)\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.title(train.loc[i, 'IDENTITY'], fontsize=12)\n",
    "    plt.axis('off')\n",
    "# Adjusts the subplot layout parameters\n",
    "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data by checking for null values\n",
    "print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\n",
    "print(\"Number of NaNs in validation set : \", valid['IDENTITY'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the null values from the training and testing data\n",
    "train.dropna(axis=0, inplace=True)\n",
    "valid.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the data with the label 'UNREADABLE'\n",
    "unreadable = train[train['IDENTITY'] == 'UNREADABLE']\n",
    "# resets the index of the DataFrame, and uses the default one instead\n",
    "unreadable.reset_index(inplace = True, drop=True)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    img_dir = 'F:\\Yash\\Dataset_SSOC\\train_v2\\train'+unreadable.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['IDENTITY'] != 'UNREADABLE']\n",
    "valid = valid[valid['IDENTITY'] != 'UNREADABLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting some lowercase labels to uppercase to maintain uniformity\n",
    "train['IDENTITY'] = train['IDENTITY'].str.upper()\n",
    "valid['IDENTITY'] = valid['IDENTITY'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the index to maintain uniform leveling\n",
    "train.reset_index(inplace = True, drop=True) \n",
    "valid.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    (h, w) = img.shape\n",
    "    # blank white image\n",
    "    final_img = np.ones([64, 256])*255 \n",
    "    \n",
    "    # cropping the image if the width and height are greater than \n",
    "    # 256 and 64 respectively\n",
    "    if w > 256:\n",
    "        img = img[:, :256]\n",
    "        \n",
    "    if h > 64:\n",
    "        img = img[:64, :]\n",
    "    \n",
    "    # rotating the image clockwise to bring the image shape to (x,y)\n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model 30000 images and the validating it on 3000 images\n",
    "train_size = 30000\n",
    "valid_size= 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "train_x = []\n",
    "\n",
    "for i in range(train_size):\n",
    "    img_dir = 'F:\\Yash\\Dataset_SSOC\\train_v2\\train'+train.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image/255.\n",
    "    train_x.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating\n",
    "valid_x = []\n",
    "\n",
    "for i in range(valid_size):\n",
    "    img_dir = 'F:\\Yash\\Dataset_SSOC\\validation_v2\\validation'+valid.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image/255.\n",
    "    valid_x.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .reshape(a: array_like = -1(we want numpy to figure out as the dimensions are unknown))\n",
    "train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
    "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels are converted to numbers representing each character\n",
    "# labels are then prepared for Connectionist Temporal Classification Loss (CTC Loss)\n",
    "alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n",
    "# max length of input labels\n",
    "max_str_len = 24 \n",
    "# +1 for ctc pseudo blank\n",
    "num_of_characters = len(alphabets) + 1 \n",
    "# max length of predicted labels\n",
    "num_of_timestamps = 64 \n",
    "\n",
    "\n",
    "def label_to_num(label):\n",
    "    label_num = []\n",
    "    for ch in label:\n",
    "        label_num.append(alphabets.find(ch))\n",
    "        \n",
    "    return np.array(label_num)\n",
    "\n",
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret+=alphabets[ch]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'JEBASTIN'\n",
    "print(name, '\\n',label_to_num(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y contains the true labels converted to numbers and padded with -1. \n",
    "# The length of each label is equal to max_str_len.\n",
    "train_y = np.ones([train_size, max_str_len]) * -1\n",
    "# train_label_len contains the length of each true label (without padding)\n",
    "train_label_len = np.zeros([train_size, 1])\n",
    "# train_input_len contains the length of each predicted label. \n",
    "# The length of all the predicted labels is constant i.e number of timestamps - 2.\n",
    "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n",
    "# train_output is a dummy output for ctc loss.\n",
    "train_output = np.zeros([train_size])\n",
    "\n",
    "for i in range(train_size):\n",
    "    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n",
    "    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y = np.ones([valid_size, max_str_len]) * -1\n",
    "valid_label_len = np.zeros([valid_size, 1])\n",
    "valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\n",
    "valid_output = np.zeros([valid_size])\n",
    "\n",
    "for i in range(valid_size):\n",
    "    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n",
    "    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n",
    "      '\\ntrain_input_len : ', train_input_len[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "# creating a convulation kernal by a 2D Convulation Layer\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
    "# Batch Normalization will apply a transformation that will maintain the mean\n",
    "# output close to 0 and output standard deviation close to 1\n",
    "inner = BatchNormalization()(inner)\n",
    "# applies rectified linear unit activation function\n",
    "inner = Activation('relu')(inner)\n",
    "# downsamples the input along its spatial dimensions by taking the max value over an input window\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "# with 64 filters\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# with 128 filters\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# CNN to RNN\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n",
    "\n",
    "## OUTPUT\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ctc loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\n",
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(learning_rate = 0.0001))\n",
    "\n",
    "model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n",
    "                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n",
    "                epochs=60, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(valid_x)\n",
    "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n",
    "                                   greedy=True)[0][0])\n",
    "\n",
    "prediction = []\n",
    "for i in range(valid_size):\n",
    "    prediction.append(num_to_label(decoded[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = valid.loc[0:valid_size, 'IDENTITY']\n",
    "correct_char = 0\n",
    "total_char = 0\n",
    "correct = 0\n",
    "\n",
    "for i in range(valid_size):\n",
    "    pr = prediction[i]\n",
    "    tr = y_true[i]\n",
    "    total_char += len(tr)\n",
    "    \n",
    "    for j in range(min(len(tr), len(pr))):\n",
    "        if tr[j] == pr[j]:\n",
    "            correct_char += 1\n",
    "            \n",
    "    if pr == tr :\n",
    "        correct += 1 \n",
    "    \n",
    "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
    "print('Correct words predicted      : %.2f%%' %(correct*100/valid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_test_v2.csv')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    img_dir = '/kaggle/input/handwriting-recognition/test_v2/test/'+test.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    image = preprocess(image)\n",
    "    image = image/255.\n",
    "    pred = model.predict(image.reshape(1, 256, 64, 1))\n",
    "    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n",
    "                                       greedy=True)[0][0])\n",
    "    plt.title(num_to_label(decoded[0]), fontsize=12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5d6c2be6262c78dadbf075e7ed7eef3fc1090c1044fdcff36d11e01ba01e819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
